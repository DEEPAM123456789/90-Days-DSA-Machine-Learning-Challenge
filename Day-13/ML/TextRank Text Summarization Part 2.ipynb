{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80644f5b-a3d9-4660-97bb-b5308dff0f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae30648-34f6-40b1-852b-94ebd5800af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Deepam\n",
      "[nltk_data]     Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Deepam\n",
      "[nltk_data]     Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8380bb70-2c07-43d5-a09d-b2762efd4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "root_dir = pathlib.Path(r\"D:\\Deepam\\bbc\")\n",
    "\n",
    "data = []\n",
    "\n",
    "for category_dir in root_dir.iterdir():\n",
    "    if category_dir.is_dir():\n",
    "        label = category_dir.name\n",
    "\n",
    "        for file_path in category_dir.glob(\"*.txt\"):\n",
    "            with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
    "                text = f.read()\n",
    "                data.append({\"text\": text, \"labels\": label})\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c602d379-2cee-4245-96db-fd177c2b1aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a98563d-5c56-4b2a-9a70-0d076abe861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df[df.labels == 'business']['text'].sample(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f07bb0dd-fb0c-43d2-a641-808d64a4712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(x):\n",
    "    return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff84d5eb-23b2-4250-80bf-cf9358a09303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christmas sales worst since 1981\n",
      "\n",
      "UK retail sales fell in December,\n",
      "failing to meet expectations and making it by some counts the worst\n",
      "Christmas since 1981.\n",
      "\n",
      "Retail sales dropped by 1% on the month in\n",
      "December, after a 0.6% rise in November, the Office for National\n",
      "Statistics (ONS) said.  The ONS revised the annual 2004 rate of growth\n",
      "down from the 5.9% estimated in November to 3.2%. A number of\n",
      "retailers have already reported poor figures for December.  Clothing\n",
      "retailers and non-specialist stores were the worst hit with only\n",
      "internet retailers showing any significant growth, according to the\n",
      "ONS.\n",
      "\n",
      "The last time retailers endured a tougher Christmas was 23 years\n",
      "previously, when sales plunged 1.7%.\n",
      "\n",
      "The ONS echoed an earlier\n",
      "caution from Bank of England governor Mervyn King not to read too much\n",
      "into the poor December figures.  Some analysts put a positive gloss on\n",
      "the figures, pointing out that the non-seasonally-adjusted figures\n",
      "showed a performance comparable with 2003. The November-December jump\n",
      "last year was roughly comparable with recent averages, although some\n",
      "way below the serious booms seen in the 1990s.  And figures for retail\n",
      "volume outperformed measures of actual spending, an indication that\n",
      "consumers are looking for bargains, and retailers are cutting their\n",
      "prices.\n",
      "\n",
      "However, reports from some High Street retailers highlight\n",
      "the weakness of the sector.  Morrisons, Woolworths, House of Fraser,\n",
      "Marks & Spencer and Big Food all said that the festive period was\n",
      "disappointing.\n",
      "\n",
      "And a British Retail Consortium survey found that\n",
      "Christmas 2004 was the worst for 10 years.  Yet, other retailers -\n",
      "including HMV, Monsoon, Jessops, Body Shop and Tesco - reported that\n",
      "festive sales were well up on last year.  Investec chief economist\n",
      "Philip Shaw said he did not expect the poor retail figures to have any\n",
      "immediate effect on interest rates.  \"The retail sales figures are\n",
      "very weak, but as Bank of England governor Mervyn King indicated last\n",
      "night, you don't really get an accurate impression of Christmas\n",
      "trading until about Easter,\" said Mr Shaw.  \"Our view is the Bank of\n",
      "England will keep its powder dry and wait to see the big picture.\"\n"
     ]
    }
   ],
   "source": [
    "print(wrap(doc.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c419a6ab-6e96-454d-803f-be85ef839c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(doc.iloc[0].split(\"\\n\", 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5e5eee-bf4b-4987-a564-eeadfd71f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english'),\n",
    "    norm='l1',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5920adca-5ef0-432d-a223-11847dedd9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = featurizer.fit_transform(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dada65e-d35d-4fdf-9721-c1de15d4a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0438f07e-4c2b-4900-8774-d3b4840680a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute similarity matrix\n",
    "S = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b69fd0-fe54-46a9-a8ea-a8fa769e0aad",
   "metadata": {},
   "source": [
    "\n",
    "# Cosine Similarity: Step-by-Step Example using Scikit-Learn\n",
    "\n",
    "## ðŸ”¹ 1. Import Required Libraries\n",
    "\n",
    "```python\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ 2. Define a Simple TF-IDF-like Matrix `X`\n",
    "\n",
    "```python\n",
    "X = np.array([\n",
    "    [1, 2, 0],  # Sentence 1\n",
    "    [2, 1, 0],  # Sentence 2\n",
    "    [0, 1, 3],  # Sentence 3\n",
    "])\n",
    "```\n",
    "\n",
    "This simulates a TF-IDF matrix for 3 sentences (rows) with 3 terms (columns).\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ 3. Use Scikit-learn to Compute Cosine Similarity\n",
    "\n",
    "```python\n",
    "S = cosine_similarity(X)\n",
    "print(np.round(S, 2))\n",
    "```\n",
    "\n",
    "### Output:\n",
    "\n",
    "```\n",
    "[[1.   0.8  0.27]\n",
    " [0.8  1.   0.24]\n",
    " [0.27 0.24 1.  ]]\n",
    "```\n",
    "\n",
    "This produces a **3Ã—3 similarity matrix**, where `S[i][j]` is the cosine similarity between sentence `i` and sentence `j`.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ 4. Manually Verify `cosine_similarity(X[0], X[1])`\n",
    "\n",
    "### Vectors:\n",
    "- **A** = `[1, 2, 0]`\n",
    "- **B** = `[2, 1, 0]`\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¸ Cosine Similarity Formula:\n",
    "\n",
    "$$\n",
    "cosine(A, B) = (A Â· B) / (||A|| * ||B||)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¸ Dot Product:\n",
    "\n",
    "```\n",
    "A Â· B = (1Ã—2) + (2Ã—1) + (0Ã—0) = 4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¸ Norms:\n",
    "\n",
    "$$\n",
    "||A|| = sqrt(1Â² + 2Â² + 0Â²) = sqrt(5)\n",
    "||B|| = sqrt(2Â² + 1Â² + 0Â²) = sqrt(5)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¸ Final Cosine Similarity:\n",
    "\n",
    "\n",
    "$$\n",
    "cosine(A, B) = 4 / (sqrt(5) * sqrt(5)) = 4 / 5 = 0.8\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9390ef5f-0e8c-4256-acc3-9a46dff9f6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 17)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape # this implies we have 17 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ed29448-d74d-4cff-a949-8eb15ab363a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fbe3d25-cf98-40bb-98a1-3c588a9f60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize similarity matrix\n",
    "S /= S.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88fa2400-d420-4cdb-9766-e94c7fbba132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec67c9ec-d885-404f-a7dc-185c31fcfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform transition matrix\n",
    "U = np.ones_like(S) / len(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d58a1b-63e3-43e0-a848-84fa6b612f12",
   "metadata": {},
   "source": [
    "* Step-by-Step Explanation:\n",
    "1. np.ones_like(S)\n",
    "* This creates a matrix filled with 1s that has the same shape and size as matrix S.\n",
    "* If S is a 3Ã—3 matrix, np.ones_like(S) will be:\n",
    "```python\n",
    "[[1. 1. 1.]\n",
    " [1. 1. 1.]\n",
    " [1. 1. 1.]]\n",
    "2. len(S)\n",
    "```\n",
    "* S is a square matrix (cosine similarity between sentences).\n",
    "* len(S) gives the number of rows (or sentences), say N.\n",
    "\n",
    "3. Division: np.ones_like(S) / len(S)\n",
    "* Each 1 in the matrix is divided by N.\n",
    "* So if len(S) = 3, the resulting matrix U becomes:\n",
    "```python\n",
    "[[1/3  1/3  1/3]\n",
    " [1/3  1/3  1/3]\n",
    " [1/3  1/3  1/3]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5523b985-c520-4ebd-817b-0b76adfc8883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "822045e6-cf31-4282-9839-449111875e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothed similarity matrix\n",
    "factor = 0.15\n",
    "S = (1 - factor) * S + factor * U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de66b5-9313-470c-9421-52f0a49f926b",
   "metadata": {},
   "source": [
    "ðŸŽ² Suppose:\n",
    "You have 3 sentences (n = 3), and your row-normalized similarity matrix S is:\n",
    "```python\n",
    "S = [[0.5, 0.3, 0.2],\n",
    "     [0.1, 0.6, 0.3],\n",
    "     [0.4, 0.4, 0.2]]\n",
    "Each row sums to 1 âœ…\n",
    "\n",
    "And your uniform matrix U = 1/3 everywhere:\n",
    "\n",
    "U = [[0.33, 0.33, 0.33],\n",
    "     [0.33, 0.33, 0.33],\n",
    "     [0.33, 0.33, 0.33]]\n",
    "Letâ€™s say factor = 0.15, then (1 - factor) = 0.85\n",
    "\n",
    "ðŸ§® Apply Formula:\n",
    "\n",
    "S_new = 0.85 * S + 0.15 * U\n",
    "Take row 1 as example:\n",
    "\n",
    "S_new[0] = 0.85 * [0.5, 0.3, 0.2] + 0.15 * [0.33, 0.33, 0.33]\n",
    "         = [0.425, 0.255, 0.17] + [0.0495, 0.0495, 0.0495]\n",
    "         = [0.4745, 0.3045, 0.2195]\n",
    "Now sum the row:\n",
    "\n",
    "0.4745 + 0.3045 + 0.2195 = 0.9985 â‰ˆ 1 (small numerical round-off error)\n",
    "âœ… Row still sums to 1\n",
    "\n",
    "ðŸ§  Why This Works (Mathematically)\n",
    "Youâ€™re using:\n",
    "\n",
    "S_new = (1 - d) * S + d * U\n",
    "\n",
    "Since both S and U are row-stochastic matrices (rows sum to 1), any convex combination like this will also have rows summing to 1:\n",
    "\n",
    "sum(row) = (1 - d) * 1 + d * 1 = 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "593b56d5-7a2e-4c35-91c9-88e906861ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc297aed-11cc-4616-887d-923c4a448105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the limiting / stationary distribution\n",
    "eigenvals, eigenvecs = np.linalg.eig(S.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d72ed71f-9ba0-4bd5-97f4-e6974ed31bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.24245466, 0.72108199, 0.67644122, 0.34790129,\n",
       "       0.34417302, 0.3866884 , 0.40333562, 0.41608572, 0.44238593,\n",
       "       0.63909999, 0.62556792, 0.58922572, 0.57452382, 0.48511399,\n",
       "       0.51329157, 0.52975372])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db5185be-01a9-4535-a0e0-965b4fabbe5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24206557, -0.27051337, -0.2213806 , -0.28613638, -0.25065894,\n",
       "       -0.2499217 , -0.279622  , -0.21515455, -0.2226665 , -0.22745415,\n",
       "       -0.2059112 , -0.20959727, -0.23526242, -0.24203809, -0.23663025,\n",
       "       -0.2940483 , -0.20865607])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvecs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b8858d2-5637-443d-a5f8-a38ebe83824b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24206557, -0.27051337, -0.2213806 , -0.28613638, -0.25065894,\n",
       "       -0.2499217 , -0.279622  , -0.21515455, -0.2226665 , -0.22745415,\n",
       "       -0.2059112 , -0.20959727, -0.23526242, -0.24203809, -0.23663025,\n",
       "       -0.2940483 , -0.20865607])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvecs[:,0].dot(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46e38e87-641d-42d9-a72e-b0fbf0acd01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05907327, 0.06601563, 0.05402535, 0.06982824, 0.06117038,\n",
       "       0.06099047, 0.06823848, 0.05250595, 0.05433915, 0.05550753,\n",
       "       0.05025022, 0.05114976, 0.05741304, 0.05906657, 0.05774684,\n",
       "       0.07175905, 0.05092007])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvecs[:,0] / eigenvecs[:, 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4a23e3c-6913-46cd-9d47-a242dc84cc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "limiting_dist = np.ones(len(S)) / len(S)\n",
    "threshold = 1e-8\n",
    "delta = float('inf')\n",
    "iters = 0\n",
    "while delta > threshold:\n",
    "    iters += 1\n",
    "\n",
    "    # Markov transition\n",
    "    p = limiting_dist.dot(S)\n",
    "\n",
    "    # compute change in limiting distribution\n",
    "    delta = np.abs(p - limiting_dist).sum()\n",
    "\n",
    "    # update limiting distribution\n",
    "    limiting_dist = p\n",
    "\n",
    "print(iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a3f4668-e832-4918-a745-c8fd815b8004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05907327, 0.06601563, 0.05402534, 0.06982824, 0.06117038,\n",
       "       0.06099047, 0.06823848, 0.05250595, 0.05433915, 0.05550753,\n",
       "       0.05025022, 0.05114977, 0.05741304, 0.05906657, 0.05774685,\n",
       "       0.07175905, 0.05092008])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limiting_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ce51683-ef41-4c97-9303-7c6101466162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999977"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limiting_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cfa45c5-b4b6-4c79-b011-9f739286a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9964739139677334e-08"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(eigenvecs[:,0] / eigenvecs[:,0].sum() - limiting_dist).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25fb4534-281f-4e72-bb88-05fae72db8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = limiting_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fa3f3eb-8409-43bc-a4a7-38f79985f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d6ce3d8-28c4-494a-a5cf-35166a096516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n",
      "0.07: \"The retail sales figures are very weak, but as Bank of England\n",
      "governor Mervyn King indicated last night, you don't really get an\n",
      "accurate impression of Christmas trading until about Easter,\" said Mr\n",
      "Shaw.\n",
      "0.07: A number of retailers have already reported poor figures for\n",
      "December.\n",
      "0.07: The ONS echoed an earlier caution from Bank of England governor\n",
      "Mervyn King not to read too much into the poor December figures.\n",
      "0.07: Retail sales dropped by 1% on the month in December, after a\n",
      "0.6% rise in November, the Office for National Statistics (ONS) said.\n",
      "0.06: Clothing retailers and non-specialist stores were the worst hit\n",
      "with only internet retailers showing any significant growth, according\n",
      "to the ONS.\n"
     ]
    }
   ],
   "source": [
    "# Many options for how to choose which sentence to include:\n",
    "\n",
    "# 1) top N sentences\n",
    "# 2) top N words or characters\n",
    "# 3) top X% sentences or top X% words\n",
    "# 4) sentence with scores > average score\n",
    "# 5) sentences with scores > factor * average score\n",
    "\n",
    "# You also don't have to sort. May make more sense in order.\n",
    "\n",
    "print(\"Generated summary:\")\n",
    "for i in sort_idx[:5]:\n",
    "    print(wrap(\"%.2f: %s\" % (scores[i], sents[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a31f6598-8c18-4926-85fb-0ce089882e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Christmas sales worst since 1981'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.iloc[0].split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7cd2fbe-27b8-407e-8253-8165e3862c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, factor = 0.15):\n",
    "    # extract sentences\n",
    "    sents = nltk.sent_tokenize(text)\n",
    "\n",
    "    # perform tf-idf\n",
    "    featurizer = TfidfVectorizer(\n",
    "        stop_words=stopwords.words('english'),\n",
    "        norm='l1')\n",
    "    X = featurizer.fit_transform(sents)\n",
    "\n",
    "    # compute similarity matrix\n",
    "    S = cosine_similarity(X)\n",
    "\n",
    "    # normalize similarity matrix\n",
    "    S /= S.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # uniform transition matrix\n",
    "    U = np.ones_like(S) / len(S)\n",
    "\n",
    "    # smoothed similarity matrix\n",
    "    S = (1 - factor) * S + factor * U\n",
    "\n",
    "    # find the limiting / stationary distribution\n",
    "    eigenvals, eigenvecs = np.linalg.eig(S.T)\n",
    "\n",
    "    # compute scores\n",
    "    scores = eigenvecs[:, 0] / eigenvecs[:,0].sum()\n",
    "\n",
    "    # sort the scores\n",
    "    sort_idx = np.argsort(-scores)\n",
    "\n",
    "    # print summary\n",
    "    for i in sort_idx[:5]:\n",
    "        print(wrap(\"%.2f:%s\" % (scores[i], sents[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8206322a-2cc6-451b-a185-83a7bd8f9f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11:Goodrem, Green Day and the Black Eyed Peas took home two awards\n",
      "each.\n",
      "0.10:As well as best female, Goodrem also took home the Pepsi Viewers\n",
      "Choice Award, whilst Green Day bagged the prize for best rock video\n",
      "for American Idiot.\n",
      "0.10:Other winners included Green Day, voted best group, and the Black\n",
      "Eyed Peas.\n",
      "0.10:The Black Eyed Peas won awards for best R 'n' B video and sexiest\n",
      "video, both for Hey Mama.\n",
      "0.10:Local singer and songwriter Missy Higgins took the title of\n",
      "breakthrough artist of the year, with Australian Idol winner Guy\n",
      "Sebastian taking the honours for best pop video.\n"
     ]
    }
   ],
   "source": [
    "doc = df[df.labels == 'entertainment']['text'].sample(random_state=123)\n",
    "summarize(doc.iloc[0].split(\"\\n\", 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7dacba8-494c-4dd5-aa51-a697aaa07eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Goodrem wins top female MTV prize'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.iloc[0].split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7de58-0c5d-47be-b845-c945d19cf0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
