{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e0bac8-84fa-4aab-a327-e9d87d613f40",
   "metadata": {},
   "source": [
    "## Tokenization:-\n",
    "\n",
    "* Tokenization is a fundamental step in Natural Language Processing (NLP). It involves dividing a Textual input into smaller units known as tokens.\n",
    "* These tokens can be in the form of words, characters, sub-words, or sentences.\n",
    "\n",
    "```python\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"Hello everyone. Welcome to GeeksforGeeks. You are studying NLP article.\"\n",
    "sent_tokenize(text)\n",
    "\n",
    "Output: \n",
    "\n",
    "['Hello everyone.',\n",
    " 'Welcome to GeeksforGeeks.',\n",
    " 'You are studying NLP article']\n",
    "```\n",
    "\n",
    "* To learn more on tokenization and its different types, see here:- (https://www.geeksforgeeks.org/nlp/nlp-how-tokenizing-text-sentence-words-works/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff6f23a-2466-455f-ae69-a89a2fc423ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ef5db5-7dd8-44a3-b37d-ba7e9f2fb307",
   "metadata": {},
   "source": [
    "## Stemming:- \n",
    "\n",
    "* Stemming is a method in text processing that eliminates prefixes and suffixes from words, transforming them into their fundamental or root form, The main objective of stemming is to streamline and standardize words, enhancing the effectiveness of the natural language processing tasks.\n",
    "* Simplifying words to their most basic form is called stemming, and it is made easier by stemmers or stemming algorithms. For example, \"chocolates\" becomes \"chocolate\" and \"retrieval\" becomes \"retrieve.\"\n",
    "* Stemming in natural language processing reduces words to their base or root form, aiding in text normalization for easier processing. This technique is crucial in tasks like text classification, information retrieval, and text summarization.\n",
    "* While beneficial, stemming has drawbacks, including potential impacts on text readability and occasional inaccuracies in determining the correct root form of a word.\n",
    "\n",
    "**Impletementation of Porter stemmer (a type of stemming method)**:\n",
    "\n",
    "```python\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Create a Porter Stemmer instance\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Example words for stemming\n",
    "words = [\"running\", \"jumps\", \"happily\", \"running\", \"happily\"]\n",
    "\n",
    "# Apply stemming to each word\n",
    "stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
    "\n",
    "# Print the results\n",
    "print(\"Original words:\", words)\n",
    "print(\"Stemmed words:\", stemmed_words)\n",
    "\n",
    "Output:\n",
    "\n",
    "Original words: ['running', 'jumps', 'happily', 'running', 'happily']\n",
    "Stemmed words: ['run', 'jump', 'happili', 'run', 'happili']\n",
    "```\n",
    "\n",
    "* To learn more on stemming and its different types, see here:- (https://www.geeksforgeeks.org/machine-learning/introduction-to-stemming/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc87794-e1af-43fb-9837-9bbcbc1eb158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fc959ad-086a-4699-aa5c-3e9492d35fbe",
   "metadata": {},
   "source": [
    "## Lemmatization:\n",
    "\n",
    "* Lemmatization is a fundamental text pre-processing technique widely applied in natural language processing (NLP) and machine learning.\n",
    "* Lemmatization is similar to stemming but it brings context to the words. So, it links words with similar meanings to one word.\n",
    "* Lemmatization is preferred over Stemming because lemmatization does morphological analysis of the words.\n",
    "\n",
    "**Impletementation of Lemmatization**\n",
    "```python\n",
    "# import these modules\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "\n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "\n",
    "Output:\n",
    "\n",
    "rocks : rock\n",
    "corpora : corpus\n",
    "better : good\n",
    "```\n",
    "* To learn more on Lemmatization and its different types, see here:- (https://www.geeksforgeeks.org/python/python-lemmatization-with-nltk/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee3e42d-6685-4711-8518-bfb6b3cbaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e28ca479-1bc0-4b7f-8dfb-d0c91aecdad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c784e4d-d7d3-4c72-b2a5-e2ffde8d8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b91f07d2-4c81-4e5f-8eaa-4babde78e616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"Walking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9b1083-fe4f-4d50-98f6-ba4949765424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"Walked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18f0e936-4b98-4d57-b980-8d9e699feb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"walks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "998e8c13-ef57-4db5-9739-e55fc50da082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ran'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"ran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b65e9b2-f6c8-4a5c-bc27-dc829e432fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa525663-231d-4378-bf4d-0c6d2ea44bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boss'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"bosses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "398c7dbd-e020-413b-954d-cd0e019ba2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'replac'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"replacement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "195fb04b-3211-4e17-92f8-80b7022d763b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happili'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"happily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c79aba71-1351-4d8e-96da-805d6b86a0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lemmatization', 'is', 'more', 'sophisticated', 'than', 'stemming']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Lemmatization is more sophisticated than stemming\".split()\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "447c308a-36c3-41fe-99c3-4bf3334051ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmat is more sophist than stem "
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "    print(porter.stem(token), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11138742-9ce0-45b1-a231-b7ac72d7096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmat/is/more/sophist/than/stem/"
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "    print(porter.stem(token), end=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49d7e2f7-29bf-4d10-902d-75f03f159cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmat\n",
      "is\n",
      "more\n",
      "sophist\n",
      "than\n",
      "stem\n"
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "    print(porter.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "873470d7-89de-4f0a-8da2-ae2ea240fe5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unnecessari'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"unnecessary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "280224a4-63df-450e-9981-c2fe76335996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berri'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"berry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c252082-2864-43c7-a132-84e56a9f6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da4f310d-7787-45b4-838a-a93d6588ad03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Deepam\n",
      "[nltk_data]     Shah\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d59a77-c1b9-4ad0-8f93-7e9bdb7bd2e2",
   "metadata": {},
   "source": [
    "### **Wordnet**:\n",
    "> Wordnet is a publicly available lexical database of over 200 languages that provides semantic relationships between its words. It is one of the earliest and most commonly used lemmatizer technique. It is present in the nltk library in python. It groups synonyms in the form of synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a98f15b-a33d-4751-8ef2-ee9279658e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0effafe-0a64-457d-bbf8-8e6731e8a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4da333d-641a-4cb7-9f6b-cd3c59ef52a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walking'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"walking\") # lemmatizer need parts of speech(pos) for every word,\n",
    "# if not given it by default takes pos of that word as a noun and does operates that word\n",
    "# on the basis of noun, here it takes walking as noun but it is not, it's a verb actually,\n",
    "# lemmatizer produced the same output if given incorrect pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c292c8e-0a6b-4c96-b415-da7972f09502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"walking\", pos=wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6779526-2ed8-4aca-9871-d0e1d39c3985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ea200fa-35e3-4365-a7b2-ae1ab8a6d674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\", pos=wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd85ec28-9679-4668-8708-f973033911c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"ran\", pos=wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91e351d9-ab11-4df4-8a69-101c8e97ab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mice'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"mice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65a98eb0-ab03-41c3-a994-00db062f7886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mouse'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"mice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4243c210-f721-46cf-b060-947ea480ed31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wa'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"was\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "183c0ae7-6ae6-4893-947b-bbf0c53143a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"was\", pos=wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5268724-8bfa-4f79-9645-346e4ba19913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cea58e8-71ca-4e49-90fc-d9eaa3119484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"is\", pos=wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "958bfc20-ee0a-44a0-b769-470c5eb501ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'better'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc7c01fc-73cd-4c2a-b606-8981c9ad6b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"better\", pos=wordnet.ADJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b42c03-95eb-4765-a4e4-28ff7392ca47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0cb7ebc3-fce6-4cf2-9a46-eaee6c986d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else: \n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd07eb8f-6567-4e9d-b0dd-af327e756f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Deepam Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b09c17ff-9183-4714-aa72-d823c88ee9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Donald Trump has a devoted following\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05089969-9f61-49ec-9bb8-8a4855e93a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Deepam Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7975b2e-8288-4068-9d10-9fe1e078a31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Donald', 'NNP'),\n",
       " ('Trump', 'NNP'),\n",
       " ('has', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('devoted', 'VBN'),\n",
       " ('following', 'NN')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_and_tags = nltk.pos_tag(sentence)\n",
    "words_and_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c5b8c00-9c9e-4bbb-8074-74397c663cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump have a devote following "
     ]
    }
   ],
   "source": [
    "for word, tag in words_and_tags:\n",
    "    lemma = lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag))\n",
    "    print(lemma, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e0edeca-50e9-4aa0-9bff-217c177f6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The cat was following the bird as it flew by\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf22571a-7795-41ef-adaa-149a60e6eb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('cat', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('following', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('bird', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('flew', 'VBD'),\n",
       " ('by', 'IN')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_and_tags = nltk.pos_tag(sentence) # This returns a list containing tuples, and each tuple contains eachword in the document, along with its corresponding tag\n",
    "words_and_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87345ea2-44b2-4521-bdb9-d6d9e667566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat be follow the bird a it fly by "
     ]
    }
   ],
   "source": [
    "for word, tag in words_and_tags:\n",
    "    lemma = lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag))\n",
    "    print(lemma, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c431e73-f6a9-447c-8c7f-43e14a9efe01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
